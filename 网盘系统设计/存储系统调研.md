
# 大数据存储系统
## HDFS
HDFS是一个分布式文件系统，采用主从架构，主要由NameNode和DataNode两类节点组成，NameNode是HDFS的主节点，负责管理文件系统的命名空间和文件快的映射关系。
它存储所有文件和目录的元数据（如文件名、权限、块位置等），并协调客户端对数据的访问请求。DataNode是HDFS的工作节点，负责存储实际的数据块。
具有一下优点：
1. 高容错：副本机制
2. 高吞吐：批量
3. 可扩展性：添加节点，轻松扩展HDFS的存储容量

### HDFS的工作原理
HDFS通过分布式存储和冗余机制，实现高可靠性和高可用性。

文件存储：HDFS将文件分割成固定大小的块（默认64MB或128MB），并将这些块存储在不同的DataNode上。每个块会被复制到多个DataNode，以确保数据的可靠性。

数据写入：当客户端向HDFS写入数据时，数据首先被分割成块，并通过Pipeline机制写入到多个DataNode。具体步骤如下：
1. 客户端请求NameNode：客户向NameNode请求写入文件
2. NameNode分配块和DataNode：NameNode为文件分配数据块并选择存储这些块的DataNode
3. 客户端写入数据块：客户端将数据块写入第一个DataNode，第一个DataNode再将数据块复制到第二个DataNode，以此类推
4. 数据块确认：当所有副本写入成功后，客户端接收到确认消息，表示数据写入完成。

数据读取：当客户端从HDFS读取数据时，NameNode提供数据块的位置信息，客户端直接从相应的DataNode读取数据。具体步骤如下：
1. 客户端请求NameNode：客户向NameNode请求读取文件
2. NameNode返回块位置：NameNode返回文件块所在的DataNode列表
3. 客户端读取数据块：客户端直接从DataNode读取数据块，并在本地合并这些数据块，恢复成完整的文件。

### 应用场景
数据仓库、日志存储与处理、多媒体存储（如图像、音频和视频文件等）。

### 操作命令
（put)将本地文件上传到HDFS： hdfs dfs -put 本地文件  **/路径**

（get)从HDFS下载文件到本地： hdfs dfs -get **/路径** 本地文件

⚠️注意：文件系统HDFS的存储的key是文件路径

## HBase
HBase是一个分布式的基于列式存储的数据库，它采用hdfs存储，zookeeper进行管理。HBase虽然还是以HDFS作为文件存储，但是它存储的数据不再是简单的文本文件，
而是经过HBase优化压缩过的二进制文件，所以它的存储文件通常是不能够直接查看的。
### 数据模型
NameSpace：类似于关系型数据库的DataBase概念，咩哥命名空间下有多个表。

Table：类似于关系型数据库的表的概念。不同的是，HBase定义表时只需要声明列族即可，不需要声明具体的列。这意味着，往HBase写入数据时，字段可以动态，按需指定。因此，和SQL数据相比，HBase能轻松应对字段变更的场景。

Column：HBase中每个列都由Column Family（列族）和Column Qualifier（列限定符）进行限定。建表时，只需指明列族，而列限定符无需预先定义。

Timestamp：用于表示数据的不同版本，每条数据写入时，如果不指定时间戳，系统会自动为其加上该字段。

Cell：由{rowkey, column Family:column Qualifier, timestamp} 唯一确定的单元，cell中的数据是没有类型的，**全部是字节码形式存储**。

![Resilience](./../pictures/network_storage/img_1.png)

### 架构
HBase是主从架构，Master作为主节点，Regionserver作为从节点
![Resilience](./../pictures/network_storage/img_2.png)
Zookeeper： Master 的高可用、RegionServer 的监控、元数据的入口以及集群配置的维护等

HDFS： 提供底层数据支撑

Master： 监控RegionServer，进行负载均衡；
RegionServer故障转移；
处理元数据变更；
处理region的分配或分裂；
处理增删改查请求；

RegionServer：负责存储HBase的实际数据；
管理分配给它的Region；
刷新缓存到HDFS；
维护Hlog；
执行压缩；
负责处理Region分片；

Region： 实际存储数据，HBase表会根据RowKey值被切分成不同的region存储在RegionServer中，在一个RegionServer中可以有多个不同的region

Hlog： 预写日志WAL，用于记录HBase的修改记录

MemStore： 写缓存

StoreFile： 这是在磁盘上保存原始数据的实际的物理文件，是实际的存储文件。StoreFile是以Hfile的形式存储在HDFS的

### HBase特点
1. 大： 一个表可以有数十亿行，上百万列；
2. 无模式： 每行都有一个可排序的主键和任意多的列，列可以根据需要动态的增加，同一 张表中不同的行可以有截然不同的列；
3. 面向列： 面向列（族）的存储和权限控制，列（族）独立检索；
4. 稀疏： 空（null）列并不占用存储空间，表可以设计的非常稀疏；
5. 数据多版本： 每个单元中的数据可以有多个版本，默认情况下版本号自动分配，是单元 格插入时的时间戳；
6. 数据类型单一： Hbase 中的数据都是二进制存储，没有类型。

### HBase性能
1. HBase集群的写操作吞吐量最大可以达到70000+ ops/sec，延迟在几个毫秒左右。
2. HBase集群的读操作吞吐量最大可以达到26000+ ops/sec，单台机器的吞吐量可以达到8000+ ops/sec，延迟在几毫秒到20毫秒左右‌.
3. HBase每个Cell的最大为10MB（默认）

### HBase操作
![Resilience](./../pictures/network_storage/img3.png)
![Resilience](./../pictures/network_storage/img_3.png)


### HBase适用场景
HBase虽然是基于HDFS来存储数据，但是他存储的数据都是经过自己优化索引后的数据，所以它对数据的存储是非常高效的。HBase以类似Redis的列式存储来管理数据，对数据的增删改查都非常高效，可以达到ms级别。
所以它完全可以作为传统意义上的数据库使用，适用于**大部分的OLTP的场景**。

## Ceph
对象存储：也就是**通常意义的键值存储**，其接口就是简单的GET、PUT、DEL 和其他扩展，代表主要有 Swift 、S3 以及 Gluster 等。

Ceph也支持块存储，和文件系统存储。

Ceph能扩展到支持100亿个对象，并提供良好且可预测的性能。 读写性能跟HBase差不多
ref: https://blocksandfiles.com/2020/09/22/ceph-scales-to-10-billion-objects/

