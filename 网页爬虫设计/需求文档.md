# 背景
在互联网早期，网络爬虫仅仅应用在搜索引擎中。随着大数据时代的到来，数据存储和计算越来越廉价和高效，越来越多的企业开始利用网络爬虫来获取外部数据。例如：获取政府公开数据以进行统计分析；获取公开资讯以进行舆情和热点追踪；获取竞争对手数据以进行产品和营销优化等等。

网络爬虫有时候也被称为网络机器人，或者网络蜘蛛。我们准备开发一个全网爬虫，爬取全（中文）互联网的公开网页，以构建搜索引擎和进行数据分析。

# 功能需求
1. 爬取全（中文）互联网的公开网页，以构建搜索引擎和进行数据分析
2. 去重：一方面需要对超链接 URL 去重，相同的 URL 不需要重复下载；另一方面还要对内容去重，不同 URL 但是相同内容的页面也不需要重复存储。
3. 需要遵循互联网爬虫协议，即目标网站的 robots.txt 协议，不爬取目标网站禁止爬取的内容。比如 www.zhihu.com 的 robots.txt 内容片段如下：
```shell
User-agent: bingbot
Disallow: /appview/
Disallow: /login
Disallow: /logout
Disallow: /resetpassword
Disallow: /terms
Disallow: /search
Allow: /search-special
Disallow: /notifications
Disallow: /settings
Disallow: /inbox
Disallow: /admin_inbox
Disallow: /*?guide*
```
Zhihu 约定 Bing 爬虫可以访问和不可以访问的路径都列在 robots.txt 中，其他的 Google 爬虫等也在 robots.txt 中列明。robots.txt 还可以直接禁止某个爬虫，比如淘宝就禁止了百度爬虫。
robots.txt 在域名根目录下，如 www.taobao.com/robots.txt。Bajie 应该首先获取目标网站的 robots.txt，根据爬虫协议构建要爬取的 URL 超链接列表。

# 非功能需求
1. 伸缩性(可扩展）：当未来需要增加每月爬取的网页数时，Bajie 可以灵活部署，扩大集群规模，增强其爬取网页的速度。也就是说，Bajie 必须是一个分布式爬虫。当前只需要爬取 HTML 页面即可，将来可能会扩展到图片、视频、文档等内容页面。
2. 健壮性（高可用）：互联网是一个开放的世界，也是一个混乱的世界，服务器可能会宕机，网站可能失去响应，网页 HTML 可能是错误的，链接可能有陷阱……所以 Bajie 应该能够面对各种异常，正常运行。
3. 性能：爬虫爬取页面，实际上就是对目标服务器的一次访问，如果高并发地进行访问，可能会对目标服务器造成比较大的负载压力，甚至会被目标服务器判定为 DoS 攻击。因此 Bajie 要避免对同一个域名进行并发爬取，还要根据目标服务器的承载能力增加访问延迟，即在两次爬取访问之间，增加等待时间。
4. 规模大小：需要每个月从互联网爬取的网页数为 20 亿个，平均每个页面 500KB，且网页需存储 20 年。
